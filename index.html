<html>
    <head>
        <title>AI Machine Learning</title>
        <meta charset="utf-8">
                <link rel="stylesheet" href="./style.css">
        <link rel="stylesheet" href="./button.css">
    </head>
    <body class="body">
        <div class="container">
            <div class="header_text">Nhận diện biểu cảm khuôn mặt</div>
            <button id="startBtn" class="bttn-unite bttn-md bttn-primary" type="button" onclick="init()">Start</button>
            <div id="webcam-container" class="cam_css"></div>
            <div id="label-container" class="label_css"></div>
        </div>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
        <script src="https://code.responsivevoice.org/responsivevoice.js?key=dXNK974J"></script>
        <script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/zXDl8gjGg/";

    let model, webcam, labelContainer, maxPredictions, startBtn;
    let lastLabel = '';

    // Load the image model and setup the webcam
    async function init() {
        document.getElementById("startBtn").disabled = true;
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(300, 300, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);
        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        const predictions = await model.predictTopK(webcam.canvas, 1);
        const label = predictions[0].className;
          if (label !== lastLabel) {
            lastLabel = label;
            responsiveVoice.speak(label, "Vietnamese Female");
            labelContainer.innerText = predictions[0].className;
        }
    }
</script>


    </body>
</html>